# ğŸ¤– Ask Your Docs â€“ RAG-Powered Document Q&A

Welcome to **Ask Your Docs**, a document-based chatbot that lets you upload files and instantly query them.  
It uses **hybrid retrieval (FAISS + BM25 + RRF)** and a **Groq LLM backend** to give concise answers with verified citations â€” no hallucinations.

ğŸ¯ [Live Demo](https://rag-chatbot-assistant.streamlit.app/)  

![Python](https://img.shields.io/badge/Python-3.11+-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-App-orange)
![FAISS](https://img.shields.io/badge/FAISS-VectorStore-green)
![Groq](https://img.shields.io/badge/Groq-LLM-purple)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow)

---

## âœ¨ What It Does

Think of this as your personal **AI knowledge assistant**. With your uploaded docs, it:

1. **Processes** PDF / Markdown / TXT files into clean text chunks  
2. **Indexes** them with dense embeddings (FAISS + FastEmbed)  
3. **Fuses** dense & sparse results using Reciprocal Rank Fusion  
4. **Answers** your questions *only* from the docs â€” with citations  
5. **Runs** in a Streamlit chat UI for quick interaction  

---

## ğŸ§° Tech Stack

| Tool             | Role                                   |
|------------------|----------------------------------------|
| FastEmbed        | Text embeddings (BAAI/bge-small-en-v1.5) |
| FAISS            | Vector store for similarity search |
| BM25 (rank-bm25) | Sparse keyword retrieval |
| RRF Fusion       | Combines dense & sparse hits |
| Groq (Llama 3.1) | Chat LLM backend |
| Streamlit        | Frontend UI |
| PyPDF2 / LangChain | Document parsing & chunking |

---

## ğŸ’» Run It Locally

```bash
git clone https://github.com/malindard/rag-chatbot-assistant.git
cd rag-chatbot-assistant
pip install -r requirements.txt
```

Create a `.env` file:

```env
GROQ_API_KEY=your_api_key_here
```

Run the app:

```bash
streamlit run streamlit_app.py
```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ streamlit_app.py        # Streamlit chat interface
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ document_processor.py  # PDF/MD/TXT processing & chunking
â”‚   â”œâ”€â”€ vector_store.py        # FAISS + embeddings
â”‚   â”œâ”€â”€ bm25_retriever.py      # Sparse keyword search
â”‚   â”œâ”€â”€ hybrid_retriever.py    # Reciprocal Rank Fusion
â”‚   â”œâ”€â”€ rag_system.py          # RAG engine (retrieval + LLM)
â”‚   â””â”€â”€ llm_handler.py         # Groq LLM client
â”œâ”€â”€ config.py                # Centralized configs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš ï¸ Notes

- Answers are **strictly from uploaded documents** â€” no guessing.  
- Citations appear like:  
  > â€œEmployees are entitled to 12 days of annual leave.â€ [source: policy.pdf Â§Leave Policy]  
- If a detail is missing, it will say:  
  > â€œNot specified in the provided documents.â€

---

## ğŸ“„ License

This project is open source under the **MIT License** â€” fork it, build on top, or showcase it!
